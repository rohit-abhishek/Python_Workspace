{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e5e295",
   "metadata": {},
   "source": [
    "# Using BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8cd663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitabhishek/miniconda3/envs/tensor/lib/python3.10/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub \n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e1c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\"\n",
    "encoder_url = \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-12-h-768-a-12/2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af602a",
   "metadata": {},
   "source": [
    "### Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a137b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 16:08:23.404219: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-06-24 16:08:23.404242: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-06-24 16:08:23.404248: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750761503.404259  154321 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1750761503.404276  154321 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-06-24 16:08:24.067579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bdad744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# say i have texts like \n",
    "test_text = [\"I love Python Programming\", \"I watched a nice movie with my loved ones\", \"Family eats together stays together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b099ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass these texts to bert preprocess model and it will create text embeddings for me on preprocess layer \n",
    "test_text_preprocessed = bert_preprocess_model(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd39f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_type_ids', 'input_mask', 'input_word_ids'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc0010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets quickly validate what are there in each - input_type_ids -> no much info there\n",
    "test_text_preprocessed['input_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d709ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the input_mask -> it will be CLS <each word from sentence> END; thus 1 will appear number of words + 2 times\n",
    "test_text_preprocessed['input_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877ae164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 128), dtype=int32, numpy=\n",
       "array([[  101,  1045,  2293, 18750,  4730,   102,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  1045,  3427,  1037,  3835,  3185,  2007,  2026,  3866,\n",
       "         3924,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  2155, 20323,  2362, 12237,  2362,   102,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what unique id is given by pre process layer using \n",
    "test_text_preprocessed['input_word_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfdd3c8",
   "metadata": {},
   "source": [
    "### use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679bec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pooled_output', 'sequence_output', 'encoder_outputs', 'default'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model = hub.KerasLayer(encoder_url)\n",
    "encoder_result = encoder_model(test_text_preprocessed)\n",
    "encoder_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdd0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n",
       "array([[ 0.39914095, -0.14203525,  0.90585774, ..., -0.7831942 ,\n",
       "         0.17452316,  0.9984515 ],\n",
       "       [ 0.13140345, -0.03195812,  0.28500998, ..., -0.27577803,\n",
       "         0.48111895,  0.9966459 ],\n",
       "       [ 0.02510827, -0.37099585,  0.96928924, ..., -0.3236761 ,\n",
       "         0.6680559 ,  0.9985489 ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will have text embedding vector for each sentence\n",
    "encoder_result['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
       "array([[[ 0.05904165, -0.21204107, -0.13617842, ...,  0.43750226,\n",
       "          0.502695  , -0.35996348],\n",
       "        [ 0.67073023,  0.14048934, -0.09224137, ...,  0.42108852,\n",
       "          0.4111905 , -0.5584124 ],\n",
       "        [ 0.177982  , -0.49039   , -0.38667092, ...,  0.12570134,\n",
       "         -0.27749434, -0.1599672 ],\n",
       "        ...,\n",
       "        [ 0.09613055,  0.09817474, -0.08416922, ...,  0.08347762,\n",
       "          0.40399906,  0.11006463],\n",
       "        [ 0.3815939 ,  0.06981775,  0.11602615, ...,  0.11969963,\n",
       "          0.38731116, -0.1336096 ],\n",
       "        [ 0.0785246 , -0.13976884, -0.10609226, ...,  0.23076624,\n",
       "          0.26019058,  0.10897487]],\n",
       "\n",
       "       [[ 0.16700491,  0.4335084 , -0.0428045 , ..., -0.15933742,\n",
       "         -0.01023474, -0.7103785 ],\n",
       "        [ 0.15062436,  0.09178686,  0.24406986, ..., -0.422398  ,\n",
       "          0.04714631, -0.7104563 ],\n",
       "        [ 0.48641336,  0.09894645,  0.47063   , ..., -0.22408971,\n",
       "         -0.30611068, -0.6279148 ],\n",
       "        ...,\n",
       "        [ 0.27559447,  0.72777146,  0.2081902 , ..., -0.01419657,\n",
       "         -0.10060994, -0.38492763],\n",
       "        [ 0.45080572,  0.39028445,  0.2554641 , ...,  0.23580572,\n",
       "          0.1851415 , -0.41743672],\n",
       "        [-0.16576092,  0.63543   ,  0.2365942 , ...,  0.06361865,\n",
       "         -0.02767923, -0.37930787]],\n",
       "\n",
       "       [[-0.08596914,  0.46120405,  0.5161917 , ..., -0.71844316,\n",
       "          0.15655605, -0.57843196],\n",
       "        [-0.46440804,  0.27917463, -0.03468346, ...,  0.20945045,\n",
       "          0.1562315 , -0.73747766],\n",
       "        [-0.24311277,  0.5608591 ,  0.5381873 , ..., -0.91276073,\n",
       "          0.1429915 , -0.97590977],\n",
       "        ...,\n",
       "        [ 0.10766129,  0.39239106,  0.30137962, ..., -0.42917138,\n",
       "          0.23420787, -0.54631066],\n",
       "        [ 0.1329641 ,  0.4171736 ,  0.23753142, ..., -0.35682914,\n",
       "          0.25854948, -0.48619702],\n",
       "        [ 0.13393861,  0.5000329 ,  0.4656166 , ..., -0.85331744,\n",
       "          0.05218641, -0.765569  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will have ebedding vector for each word in the sentence. Theis 3d array with 128 in second dimensions due to padding. \n",
    "encoder_result['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fb580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are using 12 encoders model therefore dimension below is 12. each encoder output is stored in this\n",
    "len(encoder_result['encoder_outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9230215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 128, 768), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last layer of encoder_outputs is same as sequence_output\n",
    "encoder_result['encoder_outputs'][-1] == encoder_result['sequence_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b5a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
