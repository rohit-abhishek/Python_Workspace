{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce8e998",
   "metadata": {},
   "source": [
    "# Use the MNIST dataset predictor model created in video 22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2318620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd9e7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = joblib.load('output/video22/mnist_conv2d.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9b5e2",
   "metadata": {},
   "source": [
    "### Post training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e3c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertor = tf.lite.TFLiteConverter.from_keras_model(model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a23696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_6')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13256687312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257118416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257122816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257128976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13256685904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257157168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257161744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257162448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1750772611.416314  272987 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1750772611.416329  272987 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-06-24 19:13:31.416860: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps\n",
      "2025-06-24 19:13:31.417290: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-06-24 19:13:31.417295: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps\n",
      "I0000 00:00:1750772611.420437  272987 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-06-24 19:13:31.421086: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-06-24 19:13:31.442812: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp_vmwqsps\n",
      "2025-06-24 19:13:31.449823: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 32964 microseconds.\n",
      "2025-06-24 19:13:31.457513: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "tflite_model = convertor.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0325cd6",
   "metadata": {},
   "source": [
    "### Apply Quantization along with tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cbbec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_6')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13256687312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257118416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257122816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257128976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13256685904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257157168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257161744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13257162448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1750772612.727340  272987 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1750772612.727352  272987 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-06-24 19:13:32.727519: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244\n",
      "2025-06-24 19:13:32.727947: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-06-24 19:13:32.727952: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244\n",
      "2025-06-24 19:13:32.731519: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-06-24 19:13:32.752444: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/kx/s0nzgxq96zgdm61_51783vnm0000gn/T/tmp6iblb244\n",
      "2025-06-24 19:13:32.759033: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 31514 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# read the model \n",
    "convertor = tf.lite.TFLiteConverter.from_keras_model(model_cnn)\n",
    "\n",
    "# apply quantization\n",
    "convertor.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# apply tf lite \n",
    "quantized_model = convertor.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204e0f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509320, 136808)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_model), len(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff95ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these 2 models\n",
    "with open('output/video49/mnist_cnn_tflite.tflite', 'wb') as fp:\n",
    "    fp.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e1dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/video49/mnist_cnn_quantized.tflite', 'wb') as fp:\n",
    "    fp.write(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a13024",
   "metadata": {},
   "source": [
    "### the accuarcy post training quantization may get affected \n",
    "### Quantization Aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccb4d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "# from tensorflow_model_optimization.python.core.keras.compat import keras   # use this when creating the model_cnn -> it will work then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fa72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7885c4b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`to_quantize` can only either be a keras Sequential or Functional model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m q_aware_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_cnn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:135\u001b[0m, in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m   quantized_layer_name_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_quantize, keras\u001b[38;5;241m.\u001b[39mSequential) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(to_quantize, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_graph_network\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m to_quantize\u001b[38;5;241m.\u001b[39m_is_graph_network\n\u001b[1;32m    134\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`to_quantize` can only either be a keras Sequential or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctional model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m   )\n\u001b[1;32m    140\u001b[0m annotated_model \u001b[38;5;241m=\u001b[39m quantize_annotate_model(to_quantize)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m quantize_apply(\n\u001b[1;32m    142\u001b[0m     annotated_model, quantized_layer_name_prefix\u001b[38;5;241m=\u001b[39mquantized_layer_name_prefix)\n",
      "\u001b[0;31mValueError\u001b[0m: `to_quantize` can only either be a keras Sequential or Functional model."
     ]
    }
   ],
   "source": [
    "q_aware_model = quantize_model(model_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec3e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
